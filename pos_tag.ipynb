{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc989917",
   "metadata": {},
   "source": [
    "### Parts of speech tag: These tags are also called as Grammatical tagging.\n",
    "--> It is the process of making up a word in text as corresponding to a particular part of speech, based on both its definition and its context.\n",
    "\n",
    "--> It is the process of labeling each word in a sentence as a Noun, verb adjective, adverb etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931e48ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"Artificial Intelligence is rapidly changing the world of cybersecurity. It helps analysts detect threats faster, but hackers are also using AI to create sophisticated attacks. We must build stronger defenses to protect our data from these evolving dangers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6c5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting paragraph into sentences(documents)  \n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54c3ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence is rapidly changing the world of cybersecurity.',\n",
       " 'It helps analysts detect threats faster, but hackers are also using AI to create sophisticated attacks.',\n",
       " 'We must build stronger defenses to protect our data from these evolving dangers.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRinting the sentences\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99749149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'rapidly',\n",
       " 'changing',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'cybersecurity',\n",
       " '.',\n",
       " 'It',\n",
       " 'helps',\n",
       " 'analysts',\n",
       " 'detect',\n",
       " 'threats',\n",
       " 'faster',\n",
       " ',',\n",
       " 'but',\n",
       " 'hackers',\n",
       " 'are',\n",
       " 'also',\n",
       " 'using',\n",
       " 'AI',\n",
       " 'to',\n",
       " 'create',\n",
       " 'sophisticated',\n",
       " 'attacks',\n",
       " '.',\n",
       " 'We',\n",
       " 'must',\n",
       " 'build',\n",
       " 'stronger',\n",
       " 'defenses',\n",
       " 'to',\n",
       " 'protect',\n",
       " 'our',\n",
       " 'data',\n",
       " 'from',\n",
       " 'these',\n",
       " 'evolving',\n",
       " 'dangers',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now converting the deocuments into simple words\n",
    "from nltk.tokenize import word_tokenize\n",
    "new_words = []\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    new_words.extend(words)\n",
    "new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9ee9c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\defaultuser0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# This downloads the specific data needed for pos_tag\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6e91cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('is', 'VBZ'), ('rapidly', 'RB'), ('changing', 'VBG'), ('the', 'DT'), ('world', 'NN'), ('of', 'IN'), ('cybersecurity', 'NN'), ('.', '.'), ('It', 'PRP'), ('helps', 'VBZ'), ('analysts', 'NNS'), ('detect', 'VBP'), ('threats', 'NNS'), ('faster', 'RBR'), (',', ','), ('but', 'CC'), ('hackers', 'NNS'), ('are', 'VBP'), ('also', 'RB'), ('using', 'VBG'), ('AI', 'NNP'), ('to', 'TO'), ('create', 'VB'), ('sophisticated', 'JJ'), ('attacks', 'NNS'), ('.', '.'), ('We', 'PRP'), ('must', 'MD'), ('build', 'VB'), ('stronger', 'JJR'), ('defenses', 'NNS'), ('to', 'TO'), ('protect', 'VB'), ('our', 'PRP$'), ('data', 'NNS'), ('from', 'IN'), ('these', 'DT'), ('evolving', 'VBG'), ('dangers', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## Now using pos_tag to findout the parts of speech for each word.\n",
    "from nltk import pos_tag\n",
    "poss_tag = nltk.pos_tag(new_words)\n",
    "print(poss_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
